# miniVAR: VQ-VAE + PixelCNN

This repository is a lightweight, teaching-scale re-implementation of the main idea from **Visual Autoregressive Modeling (VAR)**: a coarse-to-fine, next-scale prediction pipeline. Instead of heavy DiT transformers, we plug in a simple PixelCNN with a small â€œstageâ€ embedding to condition on previous scales.


<!-- ## Features
- **VQ-VAE**: Discrete latent representation learning for images
- **PixelCNN**: Powerful autoregressive prior over VQ-VAE latents
- **Multi-scale training**: Support for hierarchical latent structures
- **WandB integration**: Track experiments and visualize losses
- **Visualization tools**: Sample generation, reconstructions, and training curves
- **Configurable**: All hyperparameters and model settings in `config.py` -->

## âœ… Whatâ€™s Done
- [x] **VectorQuantizer** with classic straight-through loss + small MLPs Ï†_i for multi-scale canvas accumulation.
- [x] **VQ-VAE:** convolutional encoder/decoder for MNIST (28Ã—28â†’7Ã—7 latents).
- [x] Lightweight **PixelCNN** with masked convolutions (A â†’ B), purely unconditional.
- [x] Conditional â€œstageâ€ embedding that tells the model which up-sampling step itâ€™s at (1â†’2, 2â†’4, 4â†’7).
- [x] At each scale, we upscale previous indices, one-hot, add stage embedding, predict next indices.  

## ğŸ”§ What Can Be Improved (for future)
- [ ] Replace PixelCNN with a small Transformer or DiT block for richer inductive bias.
- [ ] Try on CIFAR-10 or a small face dataset to see generative power beyond MNIST.
- [ ] Experiment with more scales (e.g. 1â†’3â†’7â†’14â†’28).
 
## Project Structure
```
miniVAR/
â”œâ”€â”€ models/                # Model definitions (VQ-VAE, PixelCNN, VectorQuantizer)
â”œâ”€â”€ utils/                 # Training loops, visualization, and helpers
â”œâ”€â”€ train_vq_vae.py        # Script to train VQ-VAE
â”œâ”€â”€ train_pixel_cnn.py     # Script to train PixelCNN prior
â”œâ”€â”€ config.py              # Centralized configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ myminivar.ipynb        # (Optional) Jupyter notebook for experiments
```

## Installation
1. Clone the repository and navigate to the project folder:
   ```sh
   git clone <your-repo-url>
   cd miniVAR
   ```
2. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```

## Usage
### 1. Train VQ-VAE
```sh
python train_vq_vae.py
```
- Trains a VQ-VAE model on MNIST.
- Saves model weights and visualizations.

### 2. Train PixelCNN Prior
```sh
python train_pixel_cnn.py
```
- Trains a PixelCNN prior on the VQ-VAE latents.
- Generates and saves various sample visualizations.

### 3. Configuration
Edit `config.py` to change model hyperparameters, training settings, or experiment details.

### 4. Visualization
- Visualizations (samples, reconstructions, training curves) are saved as PNG files during/after training.
- Use the provided Jupyter notebook for interactive exploration.
